{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a91421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os, torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.manual_seed(42)\n",
    "cache_dir = (Path.cwd() / \"models\").resolve()\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    # else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "os.environ[\"HF_HOME\"] = str(cache_dir)\n",
    "print(f'Device: {device}')\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2-medium\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2-medium\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e83a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "torch.Size([50257, 1024])\n"
     ]
    }
   ],
   "source": [
    "gamma = model.lm_head.weight.detach()\n",
    "W, d = gamma.shape\n",
    "gamma_bar = torch.mean(gamma, dim=0)\n",
    "centered_gamma = gamma - gamma_bar\n",
    "\n",
    "### compute Cov(gamma) and tranform gamma to g ###\n",
    "cov_gamma = centered_gamma.T @ centered_gamma / W\n",
    "eigenvalues, eigenvectors = torch.linalg.eigh(cov_gamma)\n",
    "\n",
    "inv_sqrt_cov_gamma = eigenvectors @ torch.diag(1/torch.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "sqrt_cov_gamma = eigenvectors @ torch.diag(torch.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "\n",
    "# gamma is our original head and inv_sqrt_cov_gamma puts us in a causal basis\n",
    "g = gamma @ inv_sqrt_cov_gamma\n",
    "\n",
    "# maybe i confused but A_inv = sqrt_cov_gamma and A = inv_sqrt_cov_gamma for \n",
    "# l(x).T @ g(y)\n",
    "# where l(x) = lambda(x) @ A_inv and g(y) = gamma(y) @ A (referencing paper eq and presentation eq on youtube)\n",
    "print(model.config.hidden_size)\n",
    "print(g.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a901b29",
   "metadata": {},
   "source": [
    "### GPT2-Medium Issues\n",
    "- **problem:** gamma @ inv_sqrt_cov_gamma max produces nans \n",
    "- **cause:** precision issue in float32\n",
    "- **fix:** cast to float64 and then back to float32 after causal transform (gamma @ inv_sqrt_cov_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab48099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenval min: 1.1103568198223002e-07\n",
      "Eigenval max: 0.15361294150352478\n",
      "gamma min: -1.3290700912475586\n",
      "gamma max: 0.9381266236305237\n",
      "gamma @ inv_sqrt_cov_gamma min: nan\n",
      "gamma @ inv_sqrt_cov_gamma max: nan\n",
      "gamma dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "eigenval_min_max = f\"Eigenval min: {eigenvalues.min()}\\nEigenval max: {eigenvalues.max()}\"\n",
    "gamma_min_max = f\"gamma min: {gamma.min()}\\ngamma max: {gamma.max()}\"\n",
    "g_min_max = f\"gamma @ inv_sqrt_cov_gamma min: {g.min()}\\ngamma @ inv_sqrt_cov_gamma max: {g.max()}\"\n",
    "print(eigenval_min_max)\n",
    "print(gamma_min_max)\n",
    "print(g_min_max)\n",
    "print(f\"gamma dtype: {gamma.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0984f",
   "metadata": {},
   "source": [
    "### GPT2-Medium Fix\n",
    "- do gamma @ inv_sqrt_cov_gamma in float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd71f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "torch.Size([50257, 1024])\n"
     ]
    }
   ],
   "source": [
    "gamma = model.lm_head.weight.detach().double()\n",
    "W, d = gamma.shape\n",
    "gamma_bar = torch.mean(gamma, dim=0)\n",
    "centered_gamma = gamma - gamma_bar\n",
    "\n",
    "### compute Cov(gamma) and tranform gamma to g ###\n",
    "cov_gamma = centered_gamma.T @ centered_gamma / W\n",
    "eigenvalues, eigenvectors = torch.linalg.eigh(cov_gamma)\n",
    "\n",
    "inv_sqrt_cov_gamma = eigenvectors @ torch.diag(1/torch.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "sqrt_cov_gamma = eigenvectors @ torch.diag(torch.sqrt(eigenvalues)) @ eigenvectors.T\n",
    "\n",
    "# gamma is our original head and inv_sqrt_cov_gamma puts us in a causal basis\n",
    "g = gamma @ inv_sqrt_cov_gamma\n",
    "\n",
    "# maybe i confused but A_inv = sqrt_cov_gamma and A = inv_sqrt_cov_gamma for \n",
    "# l(x).T @ g(y)\n",
    "# where l(x) = lambda(x) @ A_inv and g(y) = gamma(y) @ A (referencing paper eq and presentation eq on youtube)\n",
    "print(model.config.hidden_size)\n",
    "print(g.size())\n",
    "\n",
    "\n",
    "#### cast back to float32 \n",
    "g = g.float()\n",
    "inv_sqrt_cov_gamma = inv_sqrt_cov_gamma.float()\n",
    "sqrt_cov_gamma = sqrt_cov_gamma.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f662aed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenval min: 1.0977974690670904e-07\n",
      "Eigenval max: 0.1536130006206978\n",
      "gamma min: -1.3290700912475586\n",
      "gamma max: 0.9381266236305237\n",
      "gamma @ inv_sqrt_cov_gamma min: -207.949951171875\n",
      "gamma @ inv_sqrt_cov_gamma max: 645.2638549804688\n",
      "gamma dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "eigenval_min_max = f\"Eigenval min: {eigenvalues.min()}\\nEigenval max: {eigenvalues.max()}\"\n",
    "gamma_min_max = f\"gamma min: {gamma.min()}\\ngamma max: {gamma.max()}\"\n",
    "g_min_max = f\"gamma @ inv_sqrt_cov_gamma min: {g.min()}\\ngamma @ inv_sqrt_cov_gamma max: {g.max()}\"\n",
    "print(eigenval_min_max)\n",
    "print(gamma_min_max)\n",
    "print(g_min_max)\n",
    "print(f\"gamma dtype: {gamma.dtype}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
